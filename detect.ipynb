{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test_essays.csv\ttrain_essays.csv  train_prompts.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train_essays.csv')\n",
    "test_df = pd.read_csv('./data/test_essays.csv')\n",
    "prompt_df = pd.read_csv('./data/train_prompts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00da8c32</td>\n",
       "      <td>1</td>\n",
       "      <td>The electrol college system is an unfair syste...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>011dc2bc</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear state senator, It is the utmost respect t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01c6e176</td>\n",
       "      <td>1</td>\n",
       "      <td>\"It's official: The electoral college is unfai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0202ddf9</td>\n",
       "      <td>1</td>\n",
       "      <td>The Electoral College has been kept for centur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>020a5d6d</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear senator, Retain the Electoral College. Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>fc66f374</td>\n",
       "      <td>1</td>\n",
       "      <td>The Electoral College was originally establish...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>fcb87d59</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear senator, I think that the presidential el...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>fcd93e2d</td>\n",
       "      <td>1</td>\n",
       "      <td>The electoral college is a group of electors t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>fcfe84cb</td>\n",
       "      <td>1</td>\n",
       "      <td>An electoral College compromises between elect...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>fe6ff9a5</td>\n",
       "      <td>1</td>\n",
       "      <td>There has been a fuss about the Elector Colleg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  prompt_id                                               text  \\\n",
       "5     00da8c32          1  The electrol college system is an unfair syste...   \n",
       "6     011dc2bc          1  Dear state senator, It is the utmost respect t...   \n",
       "8     01c6e176          1  \"It's official: The electoral college is unfai...   \n",
       "9     0202ddf9          1  The Electoral College has been kept for centur...   \n",
       "10    020a5d6d          1  Dear senator, Retain the Electoral College. Th...   \n",
       "...        ...        ...                                                ...   \n",
       "1360  fc66f374          1  The Electoral College was originally establish...   \n",
       "1361  fcb87d59          1  Dear senator, I think that the presidential el...   \n",
       "1364  fcd93e2d          1  The electoral college is a group of electors t...   \n",
       "1366  fcfe84cb          1  An electoral College compromises between elect...   \n",
       "1373  fe6ff9a5          1  There has been a fuss about the Elector Colleg...   \n",
       "\n",
       "      generated  \n",
       "5             0  \n",
       "6             0  \n",
       "8             0  \n",
       "9             0  \n",
       "10            0  \n",
       "...         ...  \n",
       "1360          0  \n",
       "1361          0  \n",
       "1364          0  \n",
       "1366          0  \n",
       "1373          0  \n",
       "\n",
       "[670 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['prompt_id'] != 0]\n",
    "# train_df[train_df['generated'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q keras-core --upgrade\n",
    "!pip install -q keras-nlp --upgrade\n",
    "!pip install --upgrade -q wandb git+https://github.com/soumik12345/wandb-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"  # \"jax\" or \"tensorflow\" or \"torch\" \n",
    "# os.environ[\"WANDB_SILENT\"] = \"false\" # for wandb\n",
    "\n",
    "import keras_nlp\n",
    "import keras_core as keras\n",
    "import keras_core.backend as K\n",
    "\n",
    "\n",
    "import torch\n",
    "# import jax\n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "cmap = mpl.cm.get_cmap('coolwarm')\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "# print(\"JAX:\", jax.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)\n",
    "\n",
    "# Configuration\n",
    "class CFG: \n",
    "    verbose = 0\n",
    "    \n",
    "    wandb = False\n",
    "    competition = 'llm-detect-ai-generated-text'\n",
    "    _wandb_kernel = 'awsaf49'\n",
    "    comment = 'DebertaV3-MaxSeq_200-ext_s-torch'\n",
    "    \n",
    "    preset = \"deberta_v3_base_en\"\n",
    "    sequence_length = 200\n",
    "    \n",
    "    device = 'TPU'\n",
    "    \n",
    "    seed = 42\n",
    "    \n",
    "    num_folds = 5\n",
    "    selected_folds = [0, 1, 2]\n",
    "    \n",
    "    epochs = 3\n",
    "    batch_size = 3\n",
    "    drop_remainder = True\n",
    "    cache = True\n",
    "    \n",
    "    scheduler = 'cosine'\n",
    "    \n",
    "    class_names = [\"real\", \"fake\"]\n",
    "    num_classes = len(class_names)\n",
    "    class_labels = list(range(num_classes))\n",
    "    label2name = dict(zip(class_labels, class_names))\n",
    "    name2label = {v: k for k, v in label2name.items()}\n",
    "\n",
    "keras.utils.set_random_seed(CFG.seed)\n",
    "\n",
    "def get_device():\n",
    "    \"Detect and intializes GPU/TPU automatically\"\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() \n",
    "        strategy = tf.distribute.TPUStrategy(tpu)\n",
    "        print(f'> Running on TPU', tpu.master(), end=' | ')\n",
    "        print('Num of TPUs: ', strategy.num_replicas_in_sync)\n",
    "        device=CFG.device\n",
    "    \n",
    "    except:\n",
    "        gpus = tf.config.list_logical_devices('GPU')\n",
    "        ngpu = len(gpus)\n",
    "        \n",
    "        if ngpu:\n",
    "            strategy = tf.distribute.MirroredStrategy(gpus)\n",
    "            print(\"> Running on GPU\", end=' | ')\n",
    "            print(\"Num of GPUs: \", ngpu)\n",
    "            device='GPU'\n",
    "\n",
    "        else:\n",
    "            print(\"> Running on CPU\")\n",
    "            strategy = tf.distribute.get_strategy()\n",
    "            device='CPU'\n",
    "    \n",
    "    return strategy, device\n",
    "\n",
    "strategy, CFG.device = get_device()\n",
    "CFG.replicas = strategy.num_replicas_in_sync\n",
    "\n",
    "BASE_PATH = './data'\n",
    "\n",
    "df = pd.read_csv(f'{BASE_PATH}/train_essays.csv')  # Read CSV file into a DataFrame\n",
    "df['label'] = df.generated.copy()\n",
    "df['name'] = df.generated.map(CFG.label2name)  # Map answer labels using name-to-label mapping\n",
    "\n",
    "print(\"# Train Data: {:,}\".format(len(df)))\n",
    "print(\"# Sample:\")\n",
    "display(df.head(2))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "df.name.value_counts().plot.bar(color=[cmap(0.0), cmap(0.25), cmap(0.65), cmap(0.9), cmap(1.0)])\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Class distribution for Train Data\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ext_df1 = pd.read_csv(f'{BASE_PATH}/daigt-proper-train-dataset/train_drcat_02.csv')\n",
    "ext_df2 = pd.read_csv(f'{BASE_PATH}/argugpt/argugpt.csv')[['id','text','model']]\n",
    "\n",
    "ext_df2.rename(columns={'model':'source'}, inplace=True)\n",
    "ext_df2['label'] = 1\n",
    "\n",
    "ext_df = pd.concat([\n",
    "    ext_df1[ext_df1.source=='persuade_corpus'].sample(10000),\n",
    "    ext_df1[ext_df1.source!='persuade_corpus'],\n",
    "    ext_df2,\n",
    "])\n",
    "\n",
    "# ext_real_df = ext_df[['id', 'text']].copy()\n",
    "# ext_real_df['label']  = 0\n",
    "\n",
    "# ext_fake_df = ext_df[['id', 'source_text']].copy()\n",
    "# ext_fake_df.rename(columns={\"source_text\":\"text\"}, inplace=True)\n",
    "# ext_fake_df['label']  = 1\n",
    "\n",
    "# ext_df = pd.concat([ext_real_df, ext_fake_df], axis=0)\n",
    "ext_df['name'] = ext_df.label.map(CFG.label2name)\n",
    "\n",
    "print(\"# External Data: {:,}\".format(len(ext_df)))\n",
    "print(\"# Sample:\")\n",
    "ext_df.head(2)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "ext_df.name.value_counts().plot.bar(color=[cmap(0.0), cmap(0.65)])\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Answer distribution for External Data\")\n",
    "plt.show()\n",
    "\n",
    "df = ext_df.copy().reset_index(drop=True) # pd.concat([ext_df, df], axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=CFG.num_folds, shuffle=True, random_state=CFG.seed)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df['stratify'] = df.label.astype(str)+df.source.astype(str)\n",
    "\n",
    "df[\"fold\"] = -1\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['stratify'])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "df.groupby([\"fold\", \"name\", \"source\"]).size()\n",
    "\n",
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    preset=CFG.preset,\n",
    "    sequence_length=CFG.sequence_length,\n",
    ")\n",
    "\n",
    "inp = preprocessor(df.text.iloc[0])\n",
    "\n",
    "for k, v in inp.items():\n",
    "    print(k, \":\", v.shape)\n",
    "\n",
    "def preprocess_fn(text, label=None):\n",
    "    text = preprocessor(text)\n",
    "    return (text, label) if label is not None else text\n",
    "\n",
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=False, drop_remainder=True,\n",
    "                  repeat=False, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE\n",
    "    slices = (texts,) if labels is None else (texts, labels)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    ds = ds.cache() if cache else ds\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)\n",
    "    ds = ds.repeat() if repeat else ds\n",
    "    opt = tf.data.Options()\n",
    "\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)\n",
    "        opt.experimental_deterministic = False\n",
    "\n",
    "    ds = ds.with_options(opt)\n",
    "    ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "\n",
    "    return ds\n",
    "\n",
    "def get_datasets(fold):\n",
    "    train_df = df[df.fold!=fold].sample(frac=1)\n",
    "        \n",
    "    train_texts = train_df.text.tolist()\n",
    "    train_labels = train_df.label.tolist()\n",
    "    \n",
    "    train_ds = build_dataset(train_texts, train_labels,\n",
    "                             batch_size=CFG.batch_size*CFG.replicas, cache=CFG.cache,\n",
    "                             shuffle=True, drop_remainder=True, repeat=True)\n",
    "\n",
    "    valid_df = df[df.fold==fold].sample(frac=1)\n",
    "    valid_texts = valid_df.text.tolist()\n",
    "    valid_labels = valid_df.label.tolist()\n",
    "    \n",
    "    valid_ds = build_dataset(valid_texts, valid_labels,\n",
    "                             batch_size=min(CFG.batch_size*CFG.replicas, len(valid_df)), cache=CFG.cache,\n",
    "                             shuffle=False, drop_remainder=True, repeat=False)\n",
    "    \n",
    "    return (train_ds, train_df), (valid_ds, valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    api_key = user_secrets.get_secret(\"WANDB\")\n",
    "    wandb.login(key=api_key)\n",
    "    anonymous = None\n",
    "except:\n",
    "    anonymous = 'must'\n",
    "    wandb.login(anonymous=anonymous, relogin=True)\n",
    "\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "from wandb.keras import WandbModelCheckpoint\n",
    "\n",
    "def wandb_init(fold):\n",
    "    config = {k: v for k, v in dict(vars(CFG)).items() if '__' not in k}\n",
    "    config.update({\"fold\": int(fold)})\n",
    "    run = wandb.init(project=\"llm-fake-text\",\n",
    "                     name=f\"fold-{fold}|max_seq-{CFG.sequence_length}|model-{CFG.preset}\",\n",
    "                     config=config,\n",
    "                     group=CFG.comment,\n",
    "                     save_code=True)\n",
    "    return run\n",
    "\n",
    "def log_wandb():\n",
    "    wandb.log({'best_auc': best_acc, 'best_loss': best_loss, 'best_epoch': best_epoch})\n",
    "\n",
    "def get_wb_callbacks(fold):\n",
    "    wb_ckpt = WandbModelCheckpoint(f'fold{fold}.keras',\n",
    "                                   monitor='val_auc',\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='max')\n",
    "    wb_metr = wandb.keras.WandbMetricsLogger()\n",
    "    return [wb_metr, wb_ckpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
    "    lr_start, lr_max, lr_min = 0.6e-6, 0.5e-6 * batch_size, 0.3e-6\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 1, 0, 0.75\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
    "        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
    "        return lr\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
    "        plt.xlabel('epoch'); plt.ylabel('lr')\n",
    "        plt.title('LR Scheduler')\n",
    "        plt.show()\n",
    "\n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "\n",
    "_=get_lr_callback(CFG.batch_size*CFG.replicas, plot=True)\n",
    "\n",
    "def get_callbacks(fold):\n",
    "    callbacks = []\n",
    "    lr_cb = get_lr_callback(CFG.batch_size*CFG.replicas)\n",
    "    ckpt_cb = keras.callbacks.ModelCheckpoint(f'fold{fold}.keras',\n",
    "                                              monitor='val_auc',\n",
    "                                              save_best_only=True,\n",
    "                                              save_weights_only=False,\n",
    "                                              mode='max')\n",
    "    callbacks.extend([lr_cb, ckpt_cb])\n",
    "\n",
    "    if CFG.wandb:\n",
    "        wb_cbs = get_wb_callbacks(fold)\n",
    "        callbacks.extend(wb_cbs) \n",
    "        \n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    classifier = keras_nlp.models.DebertaV3Classifier.from_preset(\n",
    "        CFG.preset,\n",
    "        preprocessor=None,\n",
    "        num_classes=1\n",
    "    )\n",
    "    inputs = classifier.input\n",
    "    logits = classifier(inputs)\n",
    "        \n",
    "    outputs = keras.layers.Activation(\"sigmoid\")(logits)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.AdamW(5e-6),\n",
    "        loss=keras.losses.BinaryCrossentropy(label_smoothing=0.02),\n",
    "        metrics=[\n",
    "            keras.metrics.AUC(name=\"auc\"),\n",
    "        ],\n",
    "        jit_compile=True\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.summary()\n",
    "\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for fold in CFG.selected_folds:\n",
    "    if CFG.wandb:\n",
    "        run = wandb_init(fold)\n",
    "\n",
    "    (train_ds, train_df), (valid_ds, valid_df) = get_datasets(fold)\n",
    "    \n",
    "    callbacks = get_callbacks(fold)\n",
    "\n",
    "    print('#' * 50)\n",
    "    print(f'\\tFold: {fold + 1} | Model: {CFG.preset}\\n\\tBatch Size: {CFG.batch_size * CFG.replicas} | Scheduler: {CFG.scheduler}')\n",
    "    print(f'\\tNum Train: {len(train_df)} | Num Valid: {len(valid_df)}')\n",
    "    print('#' * 50)\n",
    "    \n",
    "    K.clear_session()\n",
    "    with strategy.scope():\n",
    "        model = build_model()\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=CFG.epochs,\n",
    "        validation_data=valid_ds,\n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=int(len(train_df) / CFG.batch_size / CFG.replicas),\n",
    "    )\n",
    "    \n",
    "    best_epoch = np.argmax(model.history.history['val_auc'])\n",
    "    best_auc = model.history.history['val_auc'][best_epoch]\n",
    "    best_loss = model.history.history['val_loss'][best_epoch]\n",
    "\n",
    "    print(f'\\n{\"=\" * 17} FOLD {fold} RESULTS {\"=\" * 17}')\n",
    "    print(f'>>>> BEST Loss  : {best_loss:.3f}\\n>>>> BEST AUC   : {best_auc:.3f}\\n>>>> BEST Epoch : {best_epoch}')\n",
    "    print('=' * 50)\n",
    "    \n",
    "    if CFG.wandb:\n",
    "        log_wandb()\n",
    "        wandb.run.finish()\n",
    "\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = model.predict(\n",
    "    valid_ds,\n",
    "    batch_size=min(CFG.batch_size * CFG.replicas * 2, len(valid_df)), # max batch size = valid size\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "pred_answers = (predictions > 0.5).astype(int).squeeze()\n",
    "true_answers = valid_df.label.values\n",
    "\n",
    "print(\"# Predictions\\n\")\n",
    "for i in range(5):\n",
    "    row = valid_df.iloc[i]\n",
    "    text  = row.text\n",
    "    pred_answer = CFG.label2name[pred_answers[i]]\n",
    "    true_answer = CFG.label2name[true_answers[i]]\n",
    "    print(f\"Txt {i+1}:\\n{text[:100]} .... {text[-100:]}\\n\")\n",
    "    print(f\"True: {true_answer}\\n\")\n",
    "    print(f\"Pred: {pred_answer}\\n\")\n",
    "    print(\"-\"*90, \"\\n\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
